{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree on Imbalanced Dataset\n",
    "Imbalanced Dataset is a very common problem in data science. It is a condition where classes are not represented equally or in other words, it is a condition where one class has more instances than the others. This condition can cause several problems such as the model cannot classify the minority class, you cannot use accuracy as the performance metrics, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "The dataset used in this experiment is the Chinese Fall Detection I downloaded from Kaggle. The objective of this experiment is to classify humans' activities -  0 : Standing, 1: Walking, 2:Sitting, 3:Falling, 4:Cramps dan 5:Running<br> \n",
    "The following is the steps conducted in this project<br>\n",
    "1 Import Libraries <br>\n",
    "2 Read Dataset<br>\n",
    "3 Data Preview <br>\n",
    "4 Data Visualization<br>\n",
    "5 Preprocessing (Train - Test Split, Oversampling, Undersampling)<br>\n",
    "6 Decision Tree Model<br>\n",
    "7 Evaluation<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import statistics as stat\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from collections import Counter\n",
    "# Modules used for assessing the performance of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance Report\n",
    "def generateClassificationReport(y_test,y_pred):\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))    \n",
    "    print('accuracy is ',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data and Data Preview\n",
    "1. Data Shape\n",
    "2. Data Head and Tail\n",
    "3. Data Basic Informations\n",
    "4. Data Stats\n",
    "5. Null Value\n",
    "6. Features List\n",
    "7. Class Distribution\n",
    "8. Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1..data shape: (16382, 7)\n",
      "********************************************************************************************************************************************\n",
      "2.First 10 rows:\n",
      "   ACTIVITY      TIME         SL      EEG  BP   HR  CIRCLUATION\n",
      "0         3   4722.92    4019.64 -1600.00  13   79          317\n",
      "1         2   4059.12    2191.03 -1146.08  20   54          165\n",
      "2         2   4773.56    2787.99 -1263.38  46   67          224\n",
      "3         4   8271.27    9545.98 -2848.93  26  138          554\n",
      "4         4   7102.16   14148.80 -2381.15  85  120          809\n",
      "5         5   7015.24    7336.79 -1699.80  22   95          427\n",
      "6         3   8620.28   24949.90 -3198.06  35  157         1519\n",
      "7         3   9238.73   39245.50 -2590.00  15  196         1885\n",
      "8         0  12276.40   59742.00 -5101.00  56  249         2826\n",
      "9         4  14165.50  140950.00 -1410.00  82  315         5844\n",
      "********************************************************************************************************************************************\n",
      "3.Last 10 rows:\n",
      "       ACTIVITY      TIME         SL       EEG   BP   HR  CIRCLUATION\n",
      "16372         3   6281.68   11744.90  -1807.12   18  105          765\n",
      "16373         0  32053.90  829913.00 -17926.00  110  637        22296\n",
      "16374         2  15767.90  115821.00  -4050.00   48  271         4426\n",
      "16375         4  11468.80   87113.20  -2090.00   28  220         3450\n",
      "16376         4  13625.90   61109.90  -4440.00   27  247         2754\n",
      "16377         4   9280.68   11417.00  -3021.64   36  156          654\n",
      "16378         3   8479.69    9455.54  -2932.85   17  138          554\n",
      "16379         2   8872.53   27449.90  -2870.00   33  156         1364\n",
      "16380         4   7738.99   26466.40  -2920.24   97  156         1521\n",
      "16381         3   9368.34   39149.10  -2970.00   21  196         1885\n",
      "********************************************************************************************************************************************\n",
      "4.Basic information of the raw data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16382 entries, 0 to 16381\n",
      "Data columns (total 7 columns):\n",
      "ACTIVITY       16382 non-null int64\n",
      "TIME           16382 non-null float64\n",
      "SL             16382 non-null float64\n",
      "EEG            16382 non-null float64\n",
      "BP             16382 non-null int64\n",
      "HR             16382 non-null int64\n",
      "CIRCLUATION    16382 non-null int64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 896.0 KB\n",
      "None\n",
      "********************************************************************************************************************************************\n",
      "5.Detailed information of the raw data:\n",
      "           ACTIVITY          TIME            SL           EEG            BP  \\\n",
      "count  16382.000000  16382.000000  1.638200e+04  1.638200e+04  16382.000000   \n",
      "mean       2.361494  10936.842478  7.527198e+04 -5.621125e+03     58.251068   \n",
      "std        1.739195   5261.463601  1.275022e+05  1.082209e+05     48.292926   \n",
      "min        0.000000   1954.230000  4.222420e+01 -1.262600e+07      0.000000   \n",
      "25%        0.000000   7263.685000  9.941170e+03 -5.630000e+03     25.000000   \n",
      "50%        3.000000   9769.355000  3.118920e+04 -3.361275e+03     44.000000   \n",
      "75%        4.000000  13481.650000  8.076145e+04 -2.150000e+03     78.000000   \n",
      "max        5.000000  50895.500000  2.426140e+06  1.410000e+06    533.000000   \n",
      "\n",
      "                 HR   CIRCLUATION  \n",
      "count  16382.000000  16382.000000  \n",
      "mean     211.536992   2894.341472  \n",
      "std      129.949521   3825.927830  \n",
      "min       33.000000      5.000000  \n",
      "25%      119.000000    587.000000  \n",
      "50%      180.000000   1581.000000  \n",
      "75%      271.000000   3539.000000  \n",
      "max      986.000000  52210.000000  \n",
      "********************************************************************************************************************************************\n",
      "6.Situation of null value of raw data:\n",
      "ACTIVITY       0\n",
      "TIME           0\n",
      "SL             0\n",
      "EEG            0\n",
      "BP             0\n",
      "HR             0\n",
      "CIRCLUATION    0\n",
      "dtype: int64\n",
      "********************************************************************************************************************************************\n",
      "7.feature_name_list：\n",
      "['ACTIVITY', 'TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION']\n",
      "********************************************************************************************************************************************\n",
      "7.Distribution of class_value 'ACTIVITY':\n",
      "0    4608\n",
      "3    3588\n",
      "4    3494\n",
      "2    2502\n",
      "5    1688\n",
      "1     502\n",
      "Name: ACTIVITY, dtype: int64\n",
      "8. Feature Correlation from One Another\n",
      "             ACTIVITY      TIME        SL       EEG        BP        HR  \\\n",
      "ACTIVITY     1.000000 -0.110405 -0.146789  0.027084 -0.116499 -0.144609   \n",
      "TIME        -0.110405  1.000000  0.843200 -0.048278  0.442334  0.973901   \n",
      "SL          -0.146789  0.843200  1.000000 -0.050946  0.401064  0.859408   \n",
      "EEG          0.027084 -0.048278 -0.050946  1.000000 -0.049892 -0.050316   \n",
      "BP          -0.116499  0.442334  0.401064 -0.049892  1.000000  0.469164   \n",
      "HR          -0.144609  0.973901  0.859408 -0.050316  0.469164  1.000000   \n",
      "CIRCLUATION -0.134331  0.876956  0.978060 -0.050408  0.419356  0.904160   \n",
      "\n",
      "             CIRCLUATION  \n",
      "ACTIVITY       -0.134331  \n",
      "TIME            0.876956  \n",
      "SL              0.978060  \n",
      "EEG            -0.050408  \n",
      "BP              0.419356  \n",
      "HR              0.904160  \n",
      "CIRCLUATION     1.000000  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generate a raw data preview report\"\"\"\n",
    "import pandas as pd\n",
    "file_path = 'falldetection.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "def preview(data,class_name): #transfer into file_path and the data's class/label name (in this case, class name is ACTIVITY)  \n",
    "\n",
    "    \"\"\"1.show data shape\"\"\"\n",
    "    data_shape = data.shape\n",
    "    print(\"1..data shape:\", data_shape)\n",
    "    print(\"*******\"*20)\n",
    "    #\n",
    "    \"\"\"2.show first 10 rows and last 10 rows of data\"\"\"\n",
    "    head_10 = data.head(10)\n",
    "    print(\"2.First 10 rows:\")\n",
    "    print(head_10)\n",
    "    print(\"*******\"*20)\n",
    "    print(\"3.Last 10 rows:\")\n",
    "    tail_10 = data.tail(10)\n",
    "    print(tail_10)\n",
    "    print(\"*******\"*20)\n",
    "\n",
    "    \"\"\"3.show basic information of the raw data\"\"\"\n",
    "    print(\"4.Basic information of the raw data:\")\n",
    "    data_info = data.info()\n",
    "    print(data_info)\n",
    "    print(\"*******\"*20)\n",
    "\n",
    "    \"\"\"4.Show more detailed information of the data...\"\"\"\n",
    "    data_describe = data.describe(include = \"all\")\n",
    "    print(\"5.Detailed information of the raw data:\")\n",
    "    print(data_describe)\n",
    "    print(\"*******\"*20)\n",
    "\n",
    "    \"\"\"5.Examine null\"\"\"\n",
    "    print(\"6.Situation of null value of raw data:\")\n",
    "    data_null = data.isnull().sum()\n",
    "    print(data_null)\n",
    "    print(\"*******\" * 20)\n",
    "\n",
    "    \"\"\"6.Gain feature name(column name) list\"\"\"\n",
    "    print(\"7.feature_name_list：\")\n",
    "    features_list = data.columns.values.tolist()\n",
    "    print(features_list)\n",
    "    print(\"*******\" * 20)\n",
    "\n",
    "    \"\"\"7.Gain the distribution of class value\"\"\"\n",
    "    print(\"7.Distribution of class_value {}:\".format(repr(class_name)))\n",
    "    class_values_distribution = data[class_name].value_counts()\n",
    "    print(class_values_distribution)\n",
    "    \n",
    "    \"\"\"8 Data Correlation of Each Feature\"\"\"\n",
    "    print('8. Feature Correlation from One Another')\n",
    "    print(data.corr())\n",
    "#use function 'preview'\n",
    "preview(data,'ACTIVITY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing value in the dataset but the data distribution in each class is highly imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "In this first attempt, we try to fit the data into the model without any preprocessing step exept for Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Training and Test Data\n",
    "X = data.drop(columns=['ACTIVITY']) #<<Training Data\n",
    "y = data['ACTIVITY'].values #<<Class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "The following code is to fit the data into the model, predict with the test data and finally calculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88      1407\n",
      "           1       0.71      0.73      0.72       147\n",
      "           2       0.67      0.71      0.69       767\n",
      "           3       0.61      0.60      0.61      1051\n",
      "           4       0.56      0.60      0.58      1037\n",
      "           5       0.54      0.56      0.55       506\n",
      "\n",
      "    accuracy                           0.69      4915\n",
      "   macro avg       0.67      0.68      0.67      4915\n",
      "weighted avg       0.70      0.69      0.69      4915\n",
      "\n",
      "[[1188    1   29   59   84   46]\n",
      " [   0  108   33    2    3    1]\n",
      " [  14   37  546  117   45    8]\n",
      " [  24    4  144  633  212   34]\n",
      " [  36    2   46  180  622  151]\n",
      " [  18    0   12   42  150  284]]\n",
      "accuracy is  0.6878942014242116\n",
      "\n",
      " Accuracy:  0.6878942014242116\n"
     ]
    }
   ],
   "source": [
    "#Fitting Model, Predict, Evaluation\n",
    "model = DecisionTreeClassifier()\n",
    "acc1 = []\n",
    "model.fit(X_train, y_train)\n",
    "target_pred = model.predict(X_test)\n",
    "generateClassificationReport(y_test,target_pred)\n",
    "acc1.append(accuracy_score(y_test,target_pred))\n",
    "\n",
    "print(\"\\n Accuracy: \",stat.mean(acc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Sampling\n",
    "Oversampling is resampling the minority class so that it equals to the majority class. I use SMOTE method to oversampling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Oversampling\n",
      "[(0, 3202), (1, 348), (2, 1734), (3, 2553), (4, 2434), (5, 1196)]\n",
      "After Oversampling\n",
      "[(0, 3202), (1, 3202), (2, 3202), (3, 3202), (4, 3202), (5, 3202)]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#Apply Over Sampling\n",
    "print('Before Oversampling')\n",
    "print(sorted(Counter(y_train).items()))\n",
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "print('After Oversampling')\n",
    "print(sorted(Counter(y_train).items()))\n",
    "#Standard Scaler\n",
    "#scaler = StandardScaler()  \n",
    "#scaler.fit(X_train)  \n",
    "#X_train = scaler.transform(X_train)  \n",
    "#X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88      1406\n",
      "           1       0.64      0.81      0.71       154\n",
      "           2       0.66      0.67      0.66       768\n",
      "           3       0.61      0.60      0.60      1035\n",
      "           4       0.59      0.58      0.58      1060\n",
      "           5       0.51      0.63      0.57       492\n",
      "\n",
      "    accuracy                           0.68      4915\n",
      "   macro avg       0.66      0.69      0.67      4915\n",
      "weighted avg       0.69      0.68      0.69      4915\n",
      "\n",
      "[[1175    9   23   46   77   76]\n",
      " [   2  124   22    3    2    1]\n",
      " [  11   49  511  137   47   13]\n",
      " [  28    3  152  616  198   38]\n",
      " [  24    7   55  187  618  169]\n",
      " [  23    1   17   28  112  311]]\n",
      "accuracy is  0.6826042726347915\n",
      "\n",
      " Accuracy:  0.6826042726347915\n"
     ]
    }
   ],
   "source": [
    "#Fitting Model, Prediksi, dan Evaluasi\n",
    "model = DecisionTreeClassifier()\n",
    "acc = []\n",
    "model.fit(X_train, y_train)\n",
    "target_pred = model.predict(X_test)\n",
    "generateClassificationReport(y_test,target_pred)\n",
    "acc.append(accuracy_score(y_test,target_pred))\n",
    "\n",
    "print(\"\\n Accuracy: \",stat.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Sampling\n",
    "Undersampling is resampling the majority class so that it equals to the minority class. By using the Random Under Sampler, the data is cut randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#Apply Random Under Sampling\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_train, y_train =rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72      1393\n",
      "           1       0.53      0.79      0.63       153\n",
      "           2       0.53      0.60      0.56       725\n",
      "           3       0.53      0.49      0.51      1066\n",
      "           4       0.46      0.45      0.46      1049\n",
      "           5       0.41      0.59      0.48       529\n",
      "\n",
      "    accuracy                           0.56      4915\n",
      "   macro avg       0.55      0.59      0.56      4915\n",
      "weighted avg       0.58      0.56      0.57      4915\n",
      "\n",
      "[[889  11  66 109 169 149]\n",
      " [  2 121  17   7   3   3]\n",
      " [ 25  86 437 100  51  26]\n",
      " [ 68   5 181 521 219  72]\n",
      " [ 66   4 102 197 474 206]\n",
      " [ 39   3  19  44 111 313]]\n",
      "accuracy is  0.560528992878942\n",
      "\n",
      " Accuracy:  0.560528992878942\n"
     ]
    }
   ],
   "source": [
    "#Fitting Model, Prediksi, dan Evaluasi\n",
    "model = DecisionTreeClassifier()\n",
    "acc2 = []\n",
    "model.fit(X_train, y_train)\n",
    "target_pred = model.predict(X_test)\n",
    "generateClassificationReport(y_test,target_pred)\n",
    "acc2.append(accuracy_score(y_test,target_pred))\n",
    "\n",
    "print(\"\\n Accuracy: \",stat.mean(acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "No preprocessing and Oversampling showed almost the same performance (with only 0,01% difference) which tell us that imbalanced dataset does not affect Decision Tree’s performance. This proves the theory that Decision Tree works well with imbalanced data. On the other side, the Undersampling technique obtained a noticeably lower accuracy. This may be caused by the reducing number of datasets after undersampling was performed. Random Over Sampling means that it will randomly remove any data so that each class has the same number of data as the minority class (in this case, Class ‘1’ with 502 rows). Random Over Sampling is an easy method but we may lose important data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6878942014242116\n",
      "0.6826042726347915\n",
      "0.560528992878942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(stat.mean(acc1))\n",
    "print(stat.mean(acc))\n",
    "print(stat.mean(acc2))\n",
    "\n",
    "data = {'No Preprocessing': stat.mean(acc1), 'Oversampling': stat.mean(acc), 'Undersampling': stat.mean(acc2)}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "#fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\n",
    "plt.bar(names, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset can be downloaded on: https://www.kaggle.com/pitasr/falldata <br>\n",
    "Don't forget to cite the author:<br>\n",
    "Özdemir, Ahmet Turan, and Billur Barshan. “Detecting Falls with Wearable Sensors Using Machine Learning Techniques.” Sensors (Basel, Switzerland) 14.6 (2014): 10691–10708. PMC. Web. 23 Apr. 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
